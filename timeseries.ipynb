{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resources FB Prophet\n",
    "- https://sungkim11.medium.com/forecast-sales-using-prophet-with-regressors-b19adf8080ab\n",
    "- https://medium.com/grabngoinfo/multivariate-time-series-forecasting-with-seasonality-and-holiday-effect-using-prophet-in-python-d5d4150eeb57\n",
    "- https://medium.com/mlearning-ai/multivariate-time-series-forecasting-using-fbprophet-66147f049e66\n",
    "- https://www.analyticsvidhya.com/blog/2022/04/an-end-to-end-guide-on-time-series-forecasting-using-fbprophet/\n",
    "- https://facebook.github.io/prophet/docs/quick_start.html\n",
    "- https://www.jadsmkbdatalab.nl/forecasting-with-facebook-prophet-models-an-intro/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ##### Algo comparison\n",
    "- Neptune.AI: https://neptune.ai/blog/arima-vs-prophet-vs-lstm\n",
    "- Kaggle: https://www.kaggle.com/code/aaronfloreani/forecasting-btc-arima-xgboost-prophet-lstm\n",
    "- YouTube: https://www.youtube.com/watch?v=0gXeXtL_KjY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes\n",
    "- Difference between prophet & fbprophet: (From v0.6 onwards, Python 2 is no longer  supported. As of v1.0, the package name on PyPI is \"prophet\"; prior to v1.0 it was \"fbprophet\".)\n",
    "- For prediction windows we use cross validation, this is applicable to the trainig data.\n",
    "- Making predictions on the test-set that has regressors is a 'cheat', as we are predicting data we can already see. (https://sungkim11.medium.com/forecast-sales-using-prophet-with-regressors-b19adf8080ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import util\n",
    "import logging\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import plotly.graph_objs as go\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from prophet.plot import plot_plotly, plot_components_plotly, add_changepoints_to_plot\n",
    "\n",
    "\n",
    "logging.getLogger('prophet').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/pyn_m.csv')\n",
    "df.head()\n",
    "#df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Training and testing data automatically by percentage insted of manually by dates.\n",
    "x=df['ds']\n",
    "y=df['y']\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=False, random_state=42)\n",
    "train_df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso Regression = L1, Ridge Regression = L2\n",
    "- Because prophet has many places possible places for rate change, it uses L1 regularization\n",
    "- By default changepoints are only inferred for the first 80% of the time series\n",
    " - If the trend changes are being overfit (too much flexibility) or underfit (not enough flexibility), you can adjust the strength of the sparse prior using the input argument changepoint_prior_scale. By default, this parameter is set to 0.05. Increasing it will make the trend more flexible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {  \n",
    "    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
    "    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "}\n",
    "#create cutoff dates\n",
    "cutoffs = pd.to_datetime(['2013-02-15', '2013-03-15', '2013-04-15']) #Manually select dates 30 days apart\n",
    "# Generate all combinations of parameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "rmses = []  # Store the RMSEs for each params here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation to evaluate all parameters\n",
    "for params in all_params:\n",
    "    m = Prophet(**params).fit(train_df)  # Fit model with given params\n",
    "    df_cv = cross_validation(m, cutoffs=cutoffs, horizon='30 days', parallel=\"processes\")\n",
    "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "    rmses.append(df_p['rmse'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameters\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['rmse'] = rmses\n",
    "\n",
    "#best params\n",
    "best_params = all_params[np.argmin(rmses)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add country holidays model.add_country_holidays(country_name='UK')\n",
    "model = Prophet(changepoint_prior_scale=0.1, seasonality_prior_scale=10.0) #Use best parameters\n",
    "model.add_country_holidays(country_name='US')\n",
    "model.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = model.make_future_dataframe(periods=30, freq='D') #makefuture dataframe 30 days\n",
    "forecast = model.predict(future)\n",
    "plot_plotly(model, forecast)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation\n",
    "- Horizon: the time to be predicted\n",
    "-  Initial: the initial training period\n",
    "- Period: the spacing between cut-off dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we do cross-validation to assess prediction performance on a horizon of 30 days,\n",
    "# starting with 730 days of training data in the first cutoff and then making predictions after every  180 days.\n",
    "\n",
    "df_cv = cross_validation(model, initial='730 days', period='180 days', horizon = '30 days')\n",
    "df_cv.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = df_cv['cutoff'].unique()[0]\n",
    "df_cv = df_cv[df_cv['cutoff'].values == cutoff]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plot Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(facecolor='w', figsize=(10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(model.history['ds'].values, model.history['y'], 'k.')\n",
    "ax.plot(df_cv['ds'].values, df_cv['yhat'], ls='-', c='#0072B2')\n",
    "ax.fill_between(df_cv['ds'].values, df_cv['yhat_lower'],\n",
    "                df_cv['yhat_upper'], color='#0072B2',\n",
    "                alpha=0.2)\n",
    "ax.axvline(x=pd.to_datetime(cutoff), c='gray', lw=4, alpha=0.5)\n",
    "ax.set_ylabel('y')\n",
    "ax.set_xlabel('ds')\n",
    "ax.text(x=pd.to_datetime('2009-01-01'),y=12, s='Initial', color='black', #Initial training period 730 days\n",
    "       fontsize=16, fontweight='bold', alpha=0.8)\n",
    "ax.text(x=pd.to_datetime('2010-05-07'),y=12, s='Cutoff', color='black',\n",
    "       fontsize=16, fontweight='bold', alpha=0.8)\n",
    "ax.axvline(x=pd.to_datetime(cutoff) + pd.Timedelta('30 days'), c='gray', lw=4,\n",
    "           alpha=0.5, ls='--')\n",
    "ax.text(x=pd.to_datetime('2010-02-07'),y=6, s='Horizon', color='black',\n",
    "       fontsize=11, fontweight='bold', alpha=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perfomance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = performance_metrics(df_cv)\n",
    "perf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot change points\n",
    "fig = model.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), model, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkout holidays included in model training (model.train_holiday_names)\n",
    "model.train_holiday_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = model.plot_components(forecast)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('serialized_model.json', 'w') as fout:\n",
    "    fout.write(model_to_json(model)) #save model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load model and perfom inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('serialized_model.json', 'r') as fin:\n",
    "    saved_model = model_from_json(fin.read()) #load model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "735c0224a85c364a7ad8a24c2b00cf6e09ceaed88a58312ad9c18a22f79c85e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
